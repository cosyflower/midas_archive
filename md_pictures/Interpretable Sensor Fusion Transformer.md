## Interfuser


#### Abstract

**자율주행 차량의 대규모 배치는 안전 문제로 인해 지속적으로 지연되고 있습니다.**

- 한편으로는, 종합적인 장면 이해가 필수적입니다. 이러한 이해가 부족할 경우, 드문 상황이지만 복잡한 교통 상황(예: 갑작스럽게 나타나는 미확인 물체)에서 취약해질 수 있습니다.
- 그러나, 전역적 맥락(global context)에서의 추론은 여러 종류의 센서에 접근하고 이들 다중 모달 센서 신호를 적절히 융합하는 것이 필요하며, 이는 달성하기 어려운 과제입니다.
	- 다중 모델 센서 신호를 어떻게, 적절하게 융합할 수 있을까에 대한 질문이 되겠다! (이는 달성하기 굉장히 어렵다)


**이 논문에서 우리는 Interpretable Sensor Fusion Transformer (InterFuser)라는 안전 강화 자율주행 프레임워크를 제안합니다.**

- 이 프레임워크는 다중 모달 다중 뷰 센서들로부터 정보를 완전히 처리하고 융합하여 종합적인 장면 이해와 적대적 사건 탐지를 수행합니다.
- 또한, 우리 프레임워크에서 생성된 중간 해석 가능 특징들은 더 많은 의미를 제공하며, 이들을 활용하여 행동을 안전한 범위 내로 더 잘 제한할 수 있습니다.


주변 환경을 어떻게 하면 더 정확하게 인식할 수 있을까?? - 적절한 주행 결정을 내리는데 필요한 모든 정보를 포함한다. 교통 상황으로 예기치 못한 상황에서 안전하게 대응할 수 있도록 필요한 모든 정보를 포함한다. 

다양한 센서들에서 얻은 데이터를 완전하게 처리 및 융합 - 종합적인 장면 이해를 수행할 수 있도록 한다. 해석 가능한 중간 특징을 생성함으로써 단순한 행동 예측에서 벗어나, 왜 그런 행동을 했는지 이해할 수 있도록 해석이 가능한 중간 특징을 생성하는 장점을 가지고 있다. 

결과적으로 목표하고자 하는 바인 안전성을 강화할 수 있다



## Introduction

2가지 과제로 정리

1. 도로 가장 자리에서 갑자기 등장하는 보행자 혹은 적신호를 무시하고 달리는 차량과 같은 드문 사건을 어떻게 인식해야 하는지. 이는 다중 모달, 다중 뷰 센서 입력으로 장면에 대한 더 나은 이해를 요구한다 - 장면을 종합적으로 이해할 수 있는 능력이 있는지 - ==다양한 데이터를 적절하게 융합하는 능력== 
2. 의사 결정 과정을 검증하는 방법, 시스템의 정상/비정상 작동 조건과 실패 원인을 식별하는 방법으로, 이는 의사결정 시스템의 해석 가능성을 요구한다 - ==해석 가능성 그리고 시스템의 신뢰성을 높이고 문제 발생 시 빠르게 대응할 수 있도록 도와준다== 

==다양한 데이터를 적절하게 융합하여 전역적인 맥락을 이해할 수 있는지==
==해석 가능성 그리고 시스템의 신뢰성을 높이고 문제 발생 시 빠르게 대응할 수 있도록==



### 기존 Transfuser의 문제점과 global context에 대해서 

- 센서 확장성을 저해하고 LiDAR과 단일 뷰 이미지 간의 융합에만 한정됩니다. 다중 모달, 다중 뷰 센서로부터 정보를 효과적으로 융합하기 위해 단일 단계 아키텍처를 채택해서 상당한 성능 향상을 달성합니다. 

- Global context : 전체적으로 이해하고, 이해를 바탕으로 상황에 맞는 결정을 내린다. 특정 장면 혹은 개별 객체를 보는 것이 아니라, 전체 장면을 종합적으로 고려하여 판단해야 한다.
- 종합적인 전체 장면을 이해하기 위해서 모든 객체와 상황을 고려하고 주행 결정을 내릴 수 있어야 하는게 핵심이다. 다중 모달, 뷰 데이터를 융합함으로써 더 안전하고 정확한 주행 결정이 가능하다! 


## 기존의 E2E 주행 방법은

제어 신호가 어떻게 생성되는지에 대한 해석 가능성 부족 - 안전 보장 메커니즘이 거의 없다. 모델을 직접 이해하기 보다도 신경망의 작동 조건을 검증하려는 노력이 있습니다. 다양한 조건에 따라 다른 모델을 선택하는 데 도움이 되지만, 피드백 부족으로 추가적인 개선이 어려운 경우도 존재한다. 

안전 마인드 맵을 활용해서 중간의 해석 가능한 특징을 출력합니다. 주변 객체 그리고 교통 신호에 대한 정보를 제공합니다. 인식, 의사 결정 과정을 드러내면서 명확한 실패 조건 그리고 원인을 분석할 수 있게 됩니다. 중간에 해석 가능한 정보를 안전 제약 휴리스틱으로 활용 - 안전한 행동 집합 내 제한함으로써 주행의 안전성을 더욱 강화할 수 있게 된다. 

이 프레임워크에서는 다중 모달, 다중 뷰 센서로부터 정보를 융합하며, 중간 해석 가능한 특징들을 안전 제약 휴리스틱으로 제공하여 주행 안전성을 강화합니다

![[Pasted image 20240814170858.png]]